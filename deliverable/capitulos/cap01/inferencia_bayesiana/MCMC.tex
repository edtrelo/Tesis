\subsection{Monte Carlo: clásico y por cadenas de Markov}

% desarrollar en qué casos es difícil de calcular
% hablar de que es para modelos que valen la pena
En los modelos bayesianos, la integral que normaliza la distribución a posteriori 
es, en general, es difícil de calcular y por ello los métodos frecuentistas eran preferidos. 
Sin embargo, el desarrollo de poder de cómputo accesible junto con la teoría de los métodos de Monte Carlo 
que surgió a mediados del siglo XX revitalizaron el interés por la estadística Bayesiana. 

\subsubsection{Monte Carlo clásico}

Esta presentación de los métodos de Monte Carlo ha sido tomada de \cite{doucetSequentialMonteCarlo2001}, pues 
sirve el mismo propósito: presentar los filtros de partículas. Dada una variable aleatoria con función de 
distribución $f$ condicionada, el valor 
esperado de una función de tal variable está dado por

\begin{equation}\label{eq:esperanza_MC}
    I(h) = \mathbb E\left[h(x)|y\right]=\int h(x)f(x|y)dx.
\end{equation} 

Esta integral sólo puede ser evaluada analíticamente en contados casos, por lo que es 
necesario utilizar métodos de aproximación, siendo los métodos de Monte Carlo uno de 
los más usados dado su facilidad de implementación e invarianza respecto a la 
dimensionalidad de la integral.

Si se tiene la capacidad de obtener $N$ muestras independientes e idénticamente distribuidas $\{x_{(i)},i=1,...,N\}$
de $f(x|y)$, entonces se puede contruir el estimador empírico de \ref{eq:esperanza_MC} con
\begin{equation}
    I_N(h) = \frac{1}{N}\sum_{i=1}^{N}h(x^{(i)}),
\end{equation}
que resulta ser un estimador insesgado. Por la ley fuerte de los grandes números, 
\begin{equation}
    I_N(h) \to I(h)
\end{equation}
casi seguramente cuando $N\to \infty$. 

\subsubsection{Algoritmo de Metropolis-Hastings}

Dada una densidad objetivo $f$, el algoritmo de Metropolis-Hastings contruye una 
cadena de Markov con distribución límite $f$, es decir que, a la larga, al tomar 
muestras de esta cadena se está muestreando de una aproximación a la verdadera
distribución objetivo. Para implementar esta aproximación se necesita de una 
función de transición $q:S\times S\to \mathbb R$. La construcción de esta 
cadena se presenta en el algoritmo \ref{alg:Metropolis-Hastings}. La validez de este 
algoritmo ha sido ya demostrada, véase \cite{rinconElementosSimulacionEstocastica2024}. 

\begin{algorithm}
\caption{Muestreo de Metropolis-Hastings}
\label{alg:Metropolis-Hastings}
\begin{algorithmic}[1]
\vspace{0.2cm}
\Require \parbox[t]{13cm}{
    Función de densidad objetivo $f$, función de transición $q(x,y)$,
    estado inicial $x_0\in S$
}
\vspace{0.2cm}
\Ensure 
\parbox[t]{13cm}{
    Muestra de una cadena de Markov con distribución estacionaria $f$
}
\vspace{0.2cm}
\State $x \leftarrow x_0$
\For{$t\in 1,2,...$}
    \State $y \sim q(x, y)$
    \State $\alpha = \min\left\{\frac{f(y)}{f(x)}\cdot \frac{q(y,x)}{q(x,y)},\ 1\right\}$
    \State $u \sim U(0,1)$
    \If{$u \leq \alpha$}
        \State $x \leftarrow y$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}




