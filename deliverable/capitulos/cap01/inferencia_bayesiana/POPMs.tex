\subsection{Procesos de Markov parcialmente observados}

Se ha construido esta parte del trabajo a partir de \cite{kingStatisticalInferencePartially2016}.

Sea $\theta\in\Theta\subseteq \mathbb R^K$. Para cada valor fijo de $\theta$, el proceso estocástico 
$X = \{X(t,\theta)\}_{t\in T}$ representa un sistema dinámico que no puede ser observado 
directamente y cuya evolución futura depende únicamente del valor anterior inmediato. Dado un vector de 
parámetros fijo y un tiempo $\tau_i$, $i=0,...,n$, se usarán las notaciones $X_i$ para $X(t_i, \theta)$
y $X_{i:j}$ para $(X_i, X_{i+1},...,X_{j})$, respectivamente. La función de densidad del sistema en el 
tiempo actual condicionado a la evolución pasada cumple que
\begin{equation}\label{eq:MarkovProperty}
    f_{X_{j}|X_{0},...,X_{j-1}}(x_{{m}}|\ x_{0},...,x_{j-1},\theta) = f_{X_{j}|X_{j-1}}(x_{j}|x_{j-1}, \theta) = 
    \varphi(x_j|x_{j-1},\theta),
\end{equation}
para $j=1,...,m$. Es decir, $X$ es un proceso de Markov.

El proceso $X$ sólo puede ser observado indirectamente a través de otro proceso $Y = \{Y(t, \theta)\}_{t\in T_{obs}}$.
Sea $t_0\in T$ el tiempo inicial del proceso X y sean $T_{obs}=\{t_i\in T,\ i=1,...,n\}$ los tiempos en los 
que se ha observado el proceso Las variables aleatorias, tales que $t_0\leq t_1<...<t_n.$ Las variables aleatorias 
observables $Y_{1:n}$ son condicionalmente independientes dadas $X_{0:n}$ y, además, el valor actual del proceso
$Y$ depende únicamente del estado actual del proceso $X$. Para $i=1,...,n$ se cumple que 
\begin{equation}\label{eq:ObservationProbability}
    f_{Y_i|Y_{1:i-1},X_{0:i}}(y_{i}|\ y_{1:i-1}, x_{0:i}, \theta) = f_{Y_i|X_i}(y_i| x_i, \theta) = \psi(y_i|x_i, \theta).
\end{equation}
Finalmente, al tiempo $t_0$, el estado inicial del sistema está sujeto a la distribución inicial
\begin{equation}\label{eq:InitialDistribution}
    f_{X_0}(x_{0}|\theta) = \mu(\theta).
\end{equation}

\begin{definition}
    Dado un vector de parémetros $\theta \in \Theta \subseteq \mathbb R^K$, un sistema dinámico latente 
    $X$ que cumple \ref{eq:MarkovProperty} y que tiene distribución inicial \ref{eq:InitialDistribution}
    al tiempo $t_0$, del cual, además, se han recolectado las observaciones $y^* = (y_1^*,...,y_n^*)$ en 
    los tiempos $t_0\leq t_1<...<t_n$ de un modelo \ref{eq:ObservationProbability}, es un \textit{proceso de Markov 
    parcialmente observado} y, generalmente, se denota de la siguiente manera
    \begin{align}\label{eq:POMP}
       \begin{split}
        X_{i}& \sim \varphi(\cdot | X_{i-1},\theta)\\
        Y_{i}& \sim \psi(\cdot | X_i,\theta)\\
        X_0& \sim \mu(\theta).
    \end{split} 
    \end{align}
    para $i = 1,...,n$.
\end{definition}

En la literatura, a \ref{eq:POMP} también se le conoce como \textit{state-space model} 
o \textit{hidden Markov model}. En este trabajo nos referiremos a este modelo como un POMP, por
sus siglas en inglés \textit{partially observed Markov Process}. Algunas de las aplicaciones de esta clase de modelos 
pueden ser consulatadas en \cite{sarkkaBayesianFilteringSmoothing2023}, estas 
abarcan los campos de la navegación, la ingeniería, telecomunicaciones, física y 
otros más. En la epidemiología, los procesos de Markov parcialmente observados han sido 
utilizados para introducir y manejar la incertidumbre en dinámicas de enfermedades infecciosas.

Dado que la mayoría de las ocaciones el vector de parámetros es desconocido, la tarea se ha de centrar entonces 
en inferir tal vector. Para ello, dadas las observaciones del proceso, se tiene que la función de log-verosimilitud 
es
\begin{equation}
    \ell(\theta) = \log f_{Y_{1:n}}(y^*, \theta) =  \log f_{Y_1}(y^*_1|\theta) + \sum_{i=2}^n \log f_{Y_i|Y_{1:i-1}}(y^*_i|y^*_{1:i-1},\theta).
\end{equation} 

Las características del modelo POMP permiten representar cada una de las probabilidades condicionales anteriores de la siguiente forma
\begin{equation}
    \begin{split}
        f_{Y_i|Y_{1:i-1}}(y^*_i|y^*_{1:i-1},\theta) &= \int f_{Y_i|X_i}(y^*_i|x_i,\theta)f_{X_i|Y_{1:i-1}}(x_i|y^*_{1:n-1},\theta)dx_i \\
        f_{Y_1}(y^*_1|\theta) &= \int f_{Y_1|X_1}(y^*_1|x_1,\theta)f_{X_1}(x_1|\theta)dx_1.
    \end{split}
\end{equation}

Como es de esperarse, la log-verosimilitud no tiene una forma analítica para un vasto número de modelos, sin embargo, puede
ser aproximada a través del método de Monte Carlo Secuencial (algoritmo \ref{alg:BF}), que construye una 

Los algoritmos de filtrado de partículas son aproximaciones de Monte Carlo al problema 
del filtrado. Fueron desarrollados para atacar problemas no lineales para los cuales 
otros algoritmos populares, como el filtrado de Kalman, no están diseñados. En particular, 
el algoritmo Bootsrap filter (algoritmo \ref{alg:BF}) es la versión básica de los algoritmos 
de fitlrado de partículas y es suficiente para las necesidades de este trabajo. 
Para conocer más algoritmos de esta clase, y su sustentación teórica, se refiere a 
\cite{sarkkaBayesianFilteringSmoothing2023}.

\begin{algorithm}
\caption{Bootstrap filter}
\label{alg:BF}
\begin{algorithmic}[1]
\vspace{0.2cm}
\Require \parbox[t]{13cm}{
    Distribución de transición $f$, distribución de medida $g$, distribución 
    inicial $\mu$, parámetros $\theta$, observaciones $Y_{1:T}$, número 
    de partículas $N$
}
\vspace{0.2cm}
\Ensure 
\parbox[t]{13cm}{
    Estimaciones del valor esperado de los estados $X_{1:T}$
}
\vspace{0.2cm}
\State $x_0^{(i)} \sim \mu(x,\theta)$, $i=1,...,N$
\For{$t\in 1,2,...,T$}
    \State $x_t^{(i)}\sim f(x_t|x_{t-1}^{(i)})$
    \State $w_{t}^{i} \propto g(y_t|x_t^{(i)})$ 
    \State $x_t^{(i)} \sim resampling(x_t,w_t)$
    \State $\mathbb E\left(h(x_t)\right) \approx \sum_{i=1}^N w_t^{i}\cdot h(x_t^{(i)})$
\EndFor
\end{algorithmic}
\end{algorithm}

Nótese que en el algoritmo $\ref{alg:BF}$, el símbolo $\propto$ implica dos tareas, a saber,
la asignación del valor y la posterior normalización. Además, el método de remuestreo varía
según distintas implementaciones. 
