\subsection{Modelos de Markov parcialmente observados}


Sea $\btheta\in\Theta\subseteq \mathbb R^K$. Para cada valor fijo de $\btheta$, el proceso estocástico $\boldsymbol{X} = \{X(t,\btheta)\}_{t\in T}$ 
representa un sistema dinámico que no podemos observar directamente y cuya evolución futura depende únicamente del valor actual del sistema, 
\begin{equation}\label{eq:MarkovProperty}
    p(X_{\tau_{n+1}}|\ X_{\tau_0},...,X_{\tau_n},\btheta) = f(X_{\tau_{n+1}}|X_{\tau_n}, \btheta)
\end{equation}
es decir, $\boldsymbol{X}$ es un proceso de Markov, para $\tau_0<...<\tau_n<\tau_{n+1}$. En favor de la claridad, se utilizá la siguiente notación $X_i$ para denotar a  $X(t_i, \btheta)$ cuando sea claro que $\btheta$ está fijo 
y $X_{i:j}$ para aludir a $(X_i,\ X_{i+1},\ ...,\ X_j)$.\\

El proceso $\boldsymbol{X}$ sólo puede ser observado indirectamente y es través de otro proceso $\boldsymbol{Y} = \{Y(t, \btheta)\}_{t\in T_{obs}}$ donde $T_{obs}=\{t_i\in 
T,\ i=1,...,N\}$ son los tiempos en los que se realizan estas observaciones. Sea $t_0\in T$ el tiempo en que inicia el proceso $\boldsymbol{X}$ y $t_0\leq t_1 < t_2 <\ ...\ <t_{N}$. En general, el conjunto de índices de las observaciones es subconjunto de los Naturales. Las variables aleatorias observables $Y_{1:N}$ son condicionalmente independientes dadas $X_{0:N}$ y la observación al tiempo actual sólo depende del estado del sistema en tal momento,
\begin{equation}\label{eq:ObservationProbability}
    p(Y_{n}|\ Y_{1:n-1}, X_{0:n}, \btheta) = g(Y_n| X_n, \btheta) 
\end{equation}
Finalmente, al tiempo $t_0$, el estado inicial del sistema está sujeto a la distribución inicial
\begin{equation}\label{eq:InitialDistribution}
    p(X_{0}|\btheta) = \mu(\btheta)
\end{equation}

\begin{definition}
    Un sistema dinámico $X$ con conjunto de observaciones $Y$ que cumple con \ref{eq:MarkovProperty}, 
    \ref{eq:ObservationProbability} y \ref{eq:InitialDistribution} es un 
    \textit{proceso de Markov parcialmente observado}, denotado como 
    \begin{align}\label{eq:POMP}
       \begin{split}
        X_{n}&\sim f(X_{n-1},\btheta)\\
        Y_{n}&\sim g(X_n,\btheta)\\
        X_0&\sim\mu(\btheta)
    \end{split} 
    \end{align}
\end{definition}

En la literatura, a \ref{eq:POMP} también se le conoce como \textit{state-space model} 
o \textit{hidden Markov model}. Algunas de las aplicaciones de esta clase de modelos 
pueden ser consulatadas en \cite{sarkkaBayesianFilteringSmoothing2023}, estas 
abarcan los campos de la navegación, la ingeniería, telecomunicaciones, física y 
otros más.

Dado un modelo de Markov parcialmente observado (eq. \ref{eq:POMP}), se ha desarrollado
suficiente maquinaria teórica y algorítmica para realizar las siguientes tareas 
\begin{enumerate}
    \item El \textit{filtrado} consiste en obtener la distribución marginal del 
    estado al tiempo actual usando la observación actual y aquellas 
    obtenidas con anterioridad, es decir, se calcula 
    $$p(X_k|Y_{1:k}),\quad k = 1,...,N$$
    \item El \textit{suavizado} consiste en obtener la distribución marginal 
    del estado en un tiempo anterior usando todas las observaciones acumuladas hasta 
    el tiempo actual, es decir, se calcula 
    $$p(X_k|Y_{1:N}),\quad j = 1,...,N-1$$
    \item Para la \textit{predicción} se calcula la distribución marginal del estado 
    en algún tiempo futuro, es decir, se obtiene 
    $$p(X_{k+n}|Y_{1:k}),\quad k = 1,...,N,\quad n=1,2,...$$
\end{enumerate}

En este trabajo, se centra la atención en los algoritmos de filtrado 
pues estos son utilizados posteriormente para construir métodos de inferencia 
en el contexto de observaciones indirectas, 
como el \textit{particle Markov chain Monte Carlo} que será introducido 
en el capítulo 3. Las tareas de suavizado y predicción quedan fuera del 
alcance de este trabajo, pero se refiere a \cite{sarkkaBayesianFilteringSmoothing2023}
para una introducción.\\

Los algoritmos de filtrado de partículas son aproximaciones de Monte Carlo al problema 
del filtrado. Fueron desarrollados para atacar problemas no lineales para los cuales 
otros algoritmos populares, como el filtrado de Kalman, no están diseñados. En particular, 
el algoritmo Bootsrap filter (algoritmo \ref{alg:BF}) es la versión básica de los algoritmos 
de fitlrado de partículas y es suficiente para las necesidades de este trabajo. 
Para conocer más algoritmos de esta clase, y su sustentación teórica, se refiere a 
\cite{sarkkaBayesianFilteringSmoothing2023}.

\begin{algorithm}
\caption{Bootstrap filter}
\label{alg:BF}
\begin{algorithmic}[1]
\vspace{0.2cm}
\Require \parbox[t]{13cm}{
    Distribución de transición $f$, distribución de medida $g$, distribución 
    inicial $\mu$, parámetros $\theta$, observaciones $Y_{1:T}$, número 
    de partículas $N$
}
\vspace{0.2cm}
\Ensure 
\parbox[t]{13cm}{
    Estimaciones del valor esperado de los estados $X_{1:T}$
}
\vspace{0.2cm}
\State $x_0^{(i)} \sim \mu(x,\theta)$, $i=1,...,N$
\For{$t\in 1,2,...,T$}
    \State $x_t^{(i)}\sim f(x_t|x_{t-1}^{(i)})$
    \State $w_{t}^{i} \propto g(y_t|x_t^{(i)})$ 
    \State $x_t^{(i)} \sim resampling(x_t,w_t)$
    \State $\mathbb E\left(h(x_t)\right) \approx \sum_{i=1}^N w_t^{i}\cdot h(x_t^{(i)})$
\EndFor
\end{algorithmic}
\end{algorithm}

Nótese que en el algoritmo $\ref{alg:BF}$, el símbolo $\propto$ implica dos tareas, a saber,
la asignación del valor y la posterior normalización. Además, el método de remuestreo varía
según distintas implementaciones. 
